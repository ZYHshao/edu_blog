---
title: iOS MachineLearning 系列（21）——CoreML模型的更多训练模板
date: 2023-07-25
categories: 从机器学习到AI
tags: []
---
# iOS MachineLearning 系列（21）——CoreML模型的更多训练模板

前面文章中，有介绍如何训练生成定制化需求的 CoreML 模型，以图像分类为例做了演示，文章地址：

[https://my.oschina.net/u/2340880/blog/9377371](https://my.oschina.net/u/2340880/blog/9377371)

Create ML工具还提供了更多训练模版，本篇文章将系统的对其用法进行介绍。

## 一.Object Detection类的模型训练

之前我们也有使用过Object Detection类的模型，Object Detection，顾名思义为对象识别。即可以将一张图片中的某个对象识别出来，分析出对象的标签以及标识处对象所在图片中的位置。Object Detection最常用的模型有人脸识别模型，交通信号灯识别模型，动物识别模型等。当然，已经训练好的这些模型不一定能够满足我们需求，还以动漫角色为例，假如我们的应用需要能识别出某个图片中的某个动漫角色人物，并分析出其所在图片的位置，就可以自主来训练Object Detection类的模型。

使用Create ML工具时，视觉类模型训练的步骤基本都是一致的，我们只需要提供一组训练数据和一组测试数据，在进行一些参数配置即可。详情可以参考本系列的上一篇文章。在训练某个模型时，我们最需要关注的其实就是数据的输入格式和参数的配置。

Object Detection类的模型训练大致可以分为如下几步：

1.  收集数据足够多，且差异性覆盖足够的一组图片集（大部分数据类模型的训练都需要）。
2.  对数据集进行处理，为每张训练图片进行注解，注解包括此图中对象的标签以及所在位置（收集到数据后，一般都需要处理才能进行训练）。
3.  按照固定的格式来整理文件和目录结构，进行训练。

下面我们来详细的介绍这几个步骤。

数据的收集无需做过多介绍，只需要指定一组正常格式的图片文件即可，将这些文件放入到一个文件夹中。我们通常会将用来训练的数据集的文件夹命名为Training Data。比较重要的一步是构建annotation.json文件，这个文件的文件名是固定的，必须命名为**annotation.json**，且与训练图片放入同一个文件夹中，其用来为每张训练图片进行标注。每个注解对象的结构如下：

```json
{
  "imagefilename": "图片文件的名字",
  "annotation": [
    {
      "coordinates": {
        "y": 0.0,
        "x": 0.0,
        "height": 199.0,
        "width": 199.0
      },
      "label": "标签名"
    }
  ]
}
```

其中，annotation可以配置为一个数组，这也就是说，Object Detection是支持一张图片中包含多个要识别的对象的，只需要正确的标志位置和标签即可。coordinates用来标记对象所在的位置和尺寸。x，y分别是相对于原点的横纵坐标位置，width和height分别设置对象的宽高。（需要注意，此处的原点为图片左上角点）。默认的尺寸坐标为像素，也支持使用比例，只需要将值都设置为0到1之间的浮点数即可。例如：

```json
{
  "imagefilename": "图片文件的名字",
  "annotation": [
    {
      "coordinates": {
        "y": 0.1,
        "x": 0.1,
        "height": 0.9,
        "width": 0.9
      },
      "label": "标签名"
    }
  ]
}
```

之后，设置Training Data进行训练即可。

## 二.Style Transfer类型的模型训练

Style Transfer类型的模型用来转换图片或视频的风格，这个模型也很常用，相机和视频滤镜经常会使用到此类模型。使用这个训练模版，我们可以训练出一个自定义的图片或视频滤镜。

Style Transfer类型的模型训练需要准备一组训练图集，并提供一张样本风格的图片，在训练时，有两个参数可以进行调节：Strength和Density。

Strength参数高，则生成的模型在应用时会保留原图更少的内容，而应用更多的样式。

Density参数设置的越高，则学习风格的精细程度越高。

## 三. Hand Pose Classification类型的模型训练

此类型的模型与Image Classification的模型训练方式是一致的，提供一个数据集，其中按照文件夹命名来对图片进行分类，进行训练即可。

## 四.ActionClassification，Hand Action Calssification类型的模型训练

这两类模型主要是用来进行动作的识别，要识别动作，简单的静态图片是无法实现的，因此训练时，需要提供视频数据，参数配置帧率，动作时长等。

## 五.SoundClassifier类型模型的训练

SoundClassifier类型模型用来进行声音的分类，训练此模型与训练Image Classification的模型类似，将数据集的声音按照类型进行分类，分别放在不同的文件夹下，文件夹的名字即是声音的类别，即可进行训练。

## 六.文本分析类型的模型训练

文本分析类型的模型的训练，主要能够训练出进行文本分类的模型。在Create ML工具中，提供了两个模版，TextClassifier和WordTager。TextClassifier模型用来进行文本分类，例如之前有使用的文本的积极性分析，只需要将本文文件（txt）放入对应的标签文件夹中，将文件夹组成数据集进行训练即可。WordTager类型的模型训练也很简单，提供一组词汇，并且进行标签标记，之前使用的词性分析即是这类方式训练出来的模型。

除了上面提到的这些标准模板外，Create ML工具还提供了训练数据表格化模型的模板。并且，上面所有提到的模型的训练，除了直接使用Create ML可视化工具外，我们也可以通过编写代码的方式来进行训练，此工具使用到的接口在CroreML框架中都有提供。