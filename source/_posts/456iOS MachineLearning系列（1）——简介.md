---
title: iOS MachineLearning系列（1）——简介
date: 2023-04-14
categories: 从机器学习到AI
tags: []
---
# iOS MachineLearning系列（1）——简介

最近，随着Chat-GPT的发布，人工智能相关的资讯和话题再次火热了起来。有了人工智能的加持，对人们的生活以及各行各业的工作都将带来效率的极大提升。目前，各种大模型的发布层出不穷，这些大模型虽然功能非常强大（如文本理解，绘图等），但对于个人来说，要跑起这样一个模型来对外提供服务还是比较困难的，其需要有非常强大的算力支持。

本系列博客，主旨在讨论使用分布式的方式来运行ML或AI相关的服务功能，在iOS平台中，系统本身就提供了ML相关的框架以及内置API接口，使用内置接口已经可以实现非常强大的AI功能，且不需要引入额外的模型，不会增大App的体积。如果有更高级的AI需求，我们也可以使用CoreML框架来运行第三方的模型，非常强大。更甚一步，如果有非常定制化的AI需求，我们也可以通过Xcode工具来自己训练模型，使用自己训练的模型来实现更加复杂的功能。

在结构上，本系列博客将从应用的角度由浅入深的进行介绍，先介绍系统API的功能，再介绍如何使用三方模型，最后讨论如何自己训练模型。希望这些文章可以起到抛砖引玉的效果，帮助你打开在iOS平台上AI应用的新思路，并充分的利用用户的设备来实现AI功能，而不是中心服务器。

## 1 - 关于Machine Learning

CoreML是iOS系统提供的机器Learning核心框架，其可以将训练好的模型轻松的集成到我们的应用中，至于模型，我们可以使用自己训练的，也可以使用三方训练好的，甚至可以将其他框架的模型转换成CoreML所需要的类型进行使用。

iOS中的Machine Learning能力可以概括为以下几个方面：

-   Machine Learning APIS
-   Create ML
-   Use Models
-   ML Converters

## 2 - Machine Learning APIS

我们知道，iOS系统本身就有一些AI功能，例如人脸识别，语音识别等，这些系统内置的功能其实也开发了API供开发者使用，我们只需要很少的代码，即可在应用中集成这些功能，包括：

-   视觉：分析图像和视频的相关功能。
-   自然语言：处理和理解文本相关的。
-   语音：语音内容识别相关的。
-   音频：音频类型识别相关的。

**与视觉相关的API功能包括有：**

图片分类：自动识别图像中的内容。

图片增强：将图像的关键部分进行突出。

图像对齐：处理图像边缘对齐。

图像相似性对比：生成特征对比图像相似性。

目标检测：在图像中找到目标物。

对象跟踪：跟踪视频中的移动对象。

轨迹检测：检测视频中运动物体的轨迹。

轮廓检测：检测图像或视频中物体的轮廓。

文本检测：检测图像中的文本区域。

文本识别：识别图像中的文本，提取文本。

人脸检测：检测图像中的人脸。

人脸追踪：实时追踪相机视频流中的人脸。

面部特征提取：检测面部特征提取人脸特征。

人脸捕获质量：比较一组图中的人脸捕获质量。

人体检测：在图片中查找人体。

身体姿势分析：分析图像中的人体姿势。

手部姿势识别：在图像中识别手部姿势。

动物识别：识别图像中的猫狗。

条形码识别：识别条形码。

矩形检测：查找图片中的矩形区域。

地平线检测：分析图片中的地平线角度。

光电流：分析对象在连续视频帧之间的运动模式。

人像细分：为图片中的人物生成无光图像。

文档分析：检测图像中包含的文本矩形区域。

**与自然语言处理相关API有：**

token化：枚举文本字符串中的单词。

语言识别：识别文本的主体语言。

打标签：对文本中的实体进行标签化。

词性标注：标注文本中实体的词性。

单词嵌入：嵌入相近词。

句子嵌入：嵌入相近句。

情绪分析：分析文本的情绪。

**与语音识别API有：**

语音识别：将语音提取成文字。

**与音频处理相关的API有：**

声音分类：将声音进行分类。

本系列的后续文章会对这些API的使用多详细介绍。

## 2 - Create ML

Create ML是Mac上提供的一种模型训练方式，其训练完成后的模型可以直接在CoreML框架上进行使用。降低了模型训练的复杂性。

Create ML支持对多种类型的数据为内容进行训练，包括图片，视频，活动，声音，文本和表格等。如果安装了Xcode，则自动也将安装Create ML工具，其中自带了很多训练模板，如下图所示：

![](https://oscimg.oschina.net/oscnet/up-8c7abfc755cd98a6987a938880b12c4a7b4.png)

关于模型的训练，也将在后续文章中做介绍。

## 3 - Use Models

自己训练模型是有一定的成本的，比如首先要有大量的用于训练的数据。Core ML社区也为开发者提供了一些训练好的模型，可以直接下载使用。可以在如下网站进行下载：

[https://developer.apple.com/machine-learning/models/](https://developer.apple.com/machine-learning/models/)

这些模型的功能还是很强大的，比如进行图像的深度预测，数字手写体识别，绘图分类，物体识别，像素分割，人类关节分析，以及查找问题的答案等等。

后续文章会介绍如何使用这些模型。

## 4. ML Converters

Core ML本身是Apple提供的模型框架，我们知道还有很多第三方的训练库，我们也可以将其他框架训练的模型转换为Core ML模型，从而集成进iOS应用。支持的库和框架包括：

-   TenscrFlow
-   PyTorch
-   XGboost
-   scikit-learn
-   LIBSVM

> 专注技术，懂的热爱，愿意分享，做个朋友
> 
> QQ：316045346